{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a30cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import prompts\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import agents\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_KEY\"))\n",
    "\n",
    "def get_data_insight(df):\n",
    "    shape = df.shape\n",
    "    \n",
    "    # cols_missing_values_sum = df.isna().sum()\n",
    "    # cols_missing_values = [k for k, v in cols_missing_values_sum.items() if v > 0]\n",
    "    \n",
    "    cols_missing_values = df.isna().sum()\n",
    "    \n",
    "    dtypes = df.dtypes\n",
    "    # description = df.describe()\n",
    "    unique_counts = df.nunique()\n",
    "    \n",
    "    insights = {\n",
    "        \"Shape\": shape,\n",
    "        \"Columns with missing values\": cols_missing_values,\n",
    "        \"Data Types\": dtypes,\n",
    "        # \"Description\": description,\n",
    "        \"Unique Counts\": unique_counts\n",
    "    }\n",
    "    \n",
    "    return insights\n",
    "    \n",
    "\n",
    "def create_initial_plan(user_prompt, train_ds_insights, test_ds_insights):\n",
    "    planner_prompt = build_planner_prompt(train_ds_insights, test_ds_insights)\n",
    "\n",
    "    plan = client.responses.create(\n",
    "        model=\"o4-mini\",\n",
    "        reasoning={\"summary\": \"auto\"},\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompts.PLANNER_AG\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{planner_prompt}\\nUser Prompt: {user_prompt}\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return (plan.output[0], plan.output[1].content[0].text)\n",
    "\n",
    "\n",
    "def build_planner_prompt(train_ds_insights, test_ds_insights):\n",
    "    valid_tasks = \", \".join(agents.Task.__args__)\n",
    "    pretty_train_insights = \"\\n\".join([f\"{k}:\\n{v}\\n\\n\" for k, v in train_ds_insights.items()])\n",
    "    pretty_test_insights = \"\\n\".join([f\"{k}:\\n{v}\\n\\n\" for k, v in test_ds_insights.items()])\n",
    "    prompt = f\"\"\"\n",
    "    {prompts.PLANNER_AG}\n",
    "    \n",
    "    For the task, choose one of the following valid task types: {valid_tasks}.\n",
    "    \n",
    "    Training dataset insights:\n",
    "    {pretty_train_insights}\n",
    "    \n",
    "    Test dataset insights:\n",
    "    {pretty_test_insights}\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f3279b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"DPtrain.csv\")\n",
    "# df = pd.read_csv(\"trainWithNull.csv\")\n",
    "# diagnostics = get_diagnostics(df)\n",
    "# diag_str = \"\\n\".join([f\"{k}:\\n{v}\" for k, v in diagnostics.items()])\n",
    "# print(diag_str)\n",
    "\n",
    "df = pd.read_csv(\"trainWithNull.csv\")\n",
    "# print(df['Cabin'].unique())\n",
    "# print(df['Embarked'].unique())\n",
    "# print(df['Embarked'].isna().sum())\n",
    "\n",
    "insights = get_data_insight(df)\n",
    "reasoning, plan = create_initial_plan(\n",
    "    user_prompt=\"Predict survival on the Titanic dataset.\",\n",
    "    train_ds_insights=insights,\n",
    "    test_ds_insights=insights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16b7cbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"plan\": [\n",
      "    {\n",
      "      \"task\": \"classification\",\n",
      "      \"target\": \"Survived\",\n",
      "      \"preprocess\": \"1. Drop irrelevant columns: PassengerId (keep externally for submission), Ticket. 2. Extract Title from Name and map rare titles to ‘Rare’. Drop Name. 3. Extract Deck from Cabin (first letter), fill missing as ‘U’. 4. Impute missing Embarked with mode. 5. Impute missing Age with median age per Title group (fallback to overall median). 6. Create FamilySize = SibSp + Parch + 1 and IsAlone = (FamilySize == 1). 7. Bin Age and Fare into quartiles or domain-specific bins. 8. One-hot encode categorical features: Sex, Embarked, Title, Deck. 9. Scale numerical features (Age, Fare, FamilySize) via StandardScaler.\",\n",
      "      \"model_selection\": \"1. Baseline: Logistic Regression (with L2 regularization). 2. Tree-based: Random Forest. 3. Gradient Boosting: XGBoost or LightGBM. Rationale: LR for interpretability; RF and GB for nonlinearities and interaction effects.\",\n",
      "      \"training\": \"1. Build a scikit-learn Pipeline: preprocessing + model. 2. Use StratifiedKFold CV (5 folds) to preserve class balance. 3. Perform hyperparameter tuning via RandomizedSearchCV or Bayesian optimization: • LR: C ∈ [0.001,10] • RF: n_estimators ∈ [100,500], max_depth ∈ [3,20], min_samples_split ∈ [2,10] • XGBoost: learning_rate ∈ [0.01,0.3], n_estimators ∈ [100,500], max_depth ∈ [3,10], subsample ∈ [0.5,1.0]. 4. Enable early stopping on a validation split for GB models.\",\n",
      "      \"evaluation\": \"1. For CV: compute accuracy, precision, recall, F1-score, ROC AUC. 2. Analyze confusion matrix and ROC curves to assess trade-offs. 3. Select best model by highest mean CV ROC AUC (and stable F1). 4. Retrain selected model on full training set. 5. Evaluate final performance on held-out test set (same metrics). 6. Inspect feature importances or coefficients for interpretability.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "**Addressing JSON Structure**\n",
      "\n",
      "I see the problem with JSON rules; the request needs a valid format with a clear plan. It suggests making an array of objects, each containing a \"step\" description or tasks. They're looking for specific keys: \"task\", \"target\", \"preprocess\", \"model_selection\", \"training\", and \"evaluation.\" It seems the intention is for \"plan\" to be an array with one object that holds these keys. So, I'll follow this structure but omit \"deployment\" since it’s not required.\n",
      "**Structuring the JSON Plan**\n",
      "\n",
      "I’m preparing a JSON plan that includes essential steps like task classification and preprocessing. The preprocessing needs to identify missing values in Age, Cabin, and Embarked and decide which columns to drop or keep for mapping. I'll also extract Titles from Names and Decks from Cabin while addressing missing values. Upon reviewing the test dataset, it appears it has the same features as the training set, which is unusual. I’ll ensure to stick with the defined schema for the JSON output.\n",
      "**Finalizing the JSON Plan**\n",
      "\n",
      "I'm outlining the steps for the plan, focusing on preprocessing by filling missing Age values with the median and deriving family size. I'll also create bins for age and fare, encode categorical variables, and standardize the features. For model selection, I plan to use baseline logistic regression, along with Random Forest and gradient boosting methods. The training phase will define a pipeline for preprocessing and model training. Finally, I'll ensure the evaluation includes metrics like ROC AUC and accuracy, then format all this into a valid JSON.\n"
     ]
    }
   ],
   "source": [
    "print(plan)\n",
    "summaries = reasoning.summary\n",
    "for summary in summaries:\n",
    "    print(summary.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundryml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
